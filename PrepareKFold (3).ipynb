{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de76d039-dbfc-4ecc-9b58-8f0e8c9399a1",
   "metadata": {},
   "source": [
    "# Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7ad82f2-b80c-469f-93d1-e7f4714592d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:42, 42.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 prepared at folds0/fold_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:22, 41.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 prepared at folds0/fold_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:00, 40.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 prepared at folds0/fold_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import KFold\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define your root directory\n",
    "ROOT_DIR = 'Methodology.2.v5i.yolo'\n",
    "TRAIN_DIR = os.path.join(ROOT_DIR, 'train')\n",
    "IMAGES_DIR = os.path.join(TRAIN_DIR, 'images')\n",
    "LABELS_DIR = os.path.join(TRAIN_DIR, 'labels')\n",
    "\n",
    "\n",
    "def create_k_fold_splits(k=3, seed=42):\n",
    "    # Get all image files\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "    all_images = [\n",
    "        f for f in os.listdir(IMAGES_DIR)\n",
    "        if os.path.splitext(f)[1].lower() in image_extensions\n",
    "    ]\n",
    "    \n",
    "    # Ensure reproducibility\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "    \n",
    "    folds = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(all_images)):\n",
    "        train_files = [all_images[i] for i in train_idx]\n",
    "        val_files = [all_images[i] for i in val_idx]\n",
    "        folds.append((train_files, val_files))\n",
    "    return folds\n",
    "\n",
    "\n",
    "def prepare_folds(folds, base_output_dir='folds'):\n",
    "    if not os.path.exists(base_output_dir):\n",
    "        os.makedirs(base_output_dir)\n",
    "    \n",
    "    for i, (train_files, val_files) in tqdm(enumerate(folds)):\n",
    "        fold_dir = os.path.join(base_output_dir, f'fold_{i+1}')\n",
    "        \n",
    "        # Define directories for training and validation images and labels\n",
    "        train_images_dir = os.path.join(fold_dir, 'train', 'images')\n",
    "        train_labels_dir = os.path.join(fold_dir, 'train', 'labels')\n",
    "        val_images_dir = os.path.join(fold_dir, 'val', 'images')\n",
    "        val_labels_dir = os.path.join(fold_dir, 'val', 'labels')\n",
    "        \n",
    "        # Create directories\n",
    "        os.makedirs(train_images_dir, exist_ok=True)\n",
    "        os.makedirs(train_labels_dir, exist_ok=True)\n",
    "        os.makedirs(val_images_dir, exist_ok=True)\n",
    "        os.makedirs(val_labels_dir, exist_ok=True)\n",
    "        \n",
    "        # Function to copy images and labels\n",
    "        def copy_files(file_list, img_target_dir, lbl_target_dir):\n",
    "            for img_file in file_list:\n",
    "                # Source paths\n",
    "                src_img = os.path.join(IMAGES_DIR, img_file)\n",
    "                src_label = os.path.join(LABELS_DIR, os.path.splitext(img_file)[0] + '.txt')\n",
    "                \n",
    "                # Destination paths\n",
    "                dst_img = os.path.join(img_target_dir, img_file)\n",
    "                dst_label = os.path.join(lbl_target_dir, os.path.splitext(img_file)[0] + '.txt')\n",
    "                \n",
    "                # Copy image\n",
    "                shutil.copy(src_img, dst_img)\n",
    "                \n",
    "                # Copy label if it exists\n",
    "                if os.path.exists(src_label):\n",
    "                    shutil.copy(src_label, dst_label)\n",
    "                else:\n",
    "                    print(f\"Warning: Label file for {img_file} does not exist.\")\n",
    "        \n",
    "        # Copy training files\n",
    "        copy_files(train_files, train_images_dir, train_labels_dir)\n",
    "        \n",
    "        # Copy validation files\n",
    "        copy_files(val_files, val_images_dir, val_labels_dir)\n",
    "        \n",
    "        # Create data.yaml for the fold\n",
    "        data_yaml = {\n",
    "            'train': 'train',\n",
    "            'val': 'val',\n",
    "            'nc': get_num_classes(),\n",
    "            'names': get_class_names()\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(fold_dir, 'data.yaml'), 'w') as f:\n",
    "            yaml.dump(data_yaml, f)\n",
    "        \n",
    "        print(f\"Fold {i+1} prepared at {fold_dir}\")\n",
    "\n",
    "\n",
    "def get_num_classes():\n",
    "    # Correct path to labels directory\n",
    "    label_files = [f for f in os.listdir(LABELS_DIR) if f.endswith('.txt')]\n",
    "    classes = set()\n",
    "    for label_file in label_files:\n",
    "        with open(os.path.join(LABELS_DIR, label_file), 'r') as f:\n",
    "            for line in f:\n",
    "                cls = int(line.strip().split()[0])\n",
    "                classes.add(cls)\n",
    "    return len(classes)\n",
    "\n",
    "\n",
    "def get_class_names():\n",
    "    return ['depth', 'length', 'width']  # Replace with your actual class names\n",
    "\n",
    "\n",
    "# Step 1: Create K-Fold splits\n",
    "folds = create_k_fold_splits(k=3, seed=42)\n",
    "\n",
    "# Step 2: Prepare directories for each fold\n",
    "prepare_folds(folds, base_output_dir='folds0')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891e0e46-ae6c-4058-801b-a30f7a49d545",
   "metadata": {},
   "source": [
    "# COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1d184ae-af8f-437a-97eb-0ab4c58aa216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 550/550 [00:11<00:00, 48.14it/s]\n",
      "Copying images: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 276/276 [00:05<00:00, 50.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 prepared at raw_data/folds/fold_1\n",
      "\n",
      "Preparing Fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 551/551 [00:11<00:00, 48.83it/s]\n",
      "Copying images: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 275/275 [00:05<00:00, 47.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 prepared at raw_data/folds/fold_2\n",
      "\n",
      "Preparing Fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 551/551 [00:11<00:00, 47.35it/s]\n",
      "Copying images: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 275/275 [00:06<00:00, 44.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 prepared at raw_data/folds/fold_3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define constants\n",
    "ROOT_DIR = 'Methodology.2.v5i.coco'\n",
    "TRAIN_DIR = os.path.join(ROOT_DIR, 'train')\n",
    "IMAGES_DIR = TRAIN_DIR\n",
    "ANNOTATIONS_FILE = os.path.join(TRAIN_DIR, '_annotations.coco.json')\n",
    "FOLDS_DIR = os.path.join(ROOT_DIR, 'folds')\n",
    "K = 3  # Number of folds\n",
    "class_names = {1: 'depth', 2: 'length', 3: 'width'}  # Adjust based on your dataset\n",
    "\n",
    "# Create folds directory\n",
    "os.makedirs(FOLDS_DIR, exist_ok=True)\n",
    "\n",
    "# Load COCO annotations\n",
    "with open(ANNOTATIONS_FILE, 'r') as f:\n",
    "    coco = json.load(f)\n",
    "\n",
    "# Get all image IDs\n",
    "image_ids = [img['id'] for img in coco['images']]\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "\n",
    "# Create a list of image dicts\n",
    "images = coco['images']\n",
    "annotations = coco['annotations']\n",
    "categories = coco['categories']\n",
    "\n",
    "# Mapping from image_id to annotations\n",
    "from collections import defaultdict\n",
    "\n",
    "image_id_to_annotations = defaultdict(list)\n",
    "for ann in annotations:\n",
    "    image_id_to_annotations[ann['image_id']].append(ann)\n",
    "\n",
    "# Perform K-Fold splitting\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(image_ids), 1):  \n",
    "    print(f\"Preparing Fold {fold}...\")\n",
    "    fold_dir = os.path.join(FOLDS_DIR, f'fold_{fold}')\n",
    "    train_fold_dir = os.path.join(fold_dir, 'train')\n",
    "    val_fold_dir = os.path.join(fold_dir, 'val')\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(os.path.join(train_fold_dir, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(train_fold_dir, 'annotations'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_fold_dir, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_fold_dir, 'annotations'), exist_ok=True)\n",
    "    \n",
    "    # Split images\n",
    "    train_images = [images[i] for i in train_idx]\n",
    "    val_images = [images[i] for i in val_idx]\n",
    "    \n",
    "    # Function to copy images and annotations\n",
    "    def copy_images_and_annotations(images_subset, target_images_dir, target_annotations_file):\n",
    "        # List to store annotations for this subset\n",
    "        subset_annotations = []\n",
    "        \n",
    "        for img in tqdm(images_subset, desc=\"Copying images\"):\n",
    "            img_id = img['id']\n",
    "            img_filename = img['file_name']\n",
    "            src_img_path = os.path.join(IMAGES_DIR, img_filename)\n",
    "            dst_img_path = os.path.join(target_images_dir, img_filename)\n",
    "            \n",
    "            # Copy image\n",
    "            shutil.copy(src_img_path, dst_img_path)\n",
    "            \n",
    "            # Get annotations for this image\n",
    "            anns = image_id_to_annotations[img_id]\n",
    "            for ann in anns:\n",
    "                subset_annotations.append(ann)\n",
    "        \n",
    "        # Create subset COCO JSON\n",
    "        subset_coco = {\n",
    "            'images': images_subset,\n",
    "            'annotations': subset_annotations,\n",
    "            'categories': categories\n",
    "        }\n",
    "        \n",
    "        # Save subset annotations\n",
    "        with open(target_annotations_file, 'w') as f:\n",
    "            json.dump(subset_coco, f)\n",
    "    \n",
    "    # Copy training set\n",
    "    copy_images_and_annotations(\n",
    "        train_images,\n",
    "        os.path.join(train_fold_dir, 'images'),\n",
    "        os.path.join(train_fold_dir, 'annotations', '_annotations.coco.json')\n",
    "    )\n",
    "    \n",
    "    # Copy validation set\n",
    "    copy_images_and_annotations(\n",
    "        val_images,\n",
    "        os.path.join(val_fold_dir, 'images'),\n",
    "        os.path.join(val_fold_dir, 'annotations', '_annotations.coco.json')\n",
    "    )\n",
    "    \n",
    "    print(f\"Fold {fold} prepared at {fold_dir}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
